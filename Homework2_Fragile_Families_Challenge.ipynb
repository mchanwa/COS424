{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework2- Fragile Families Challenge.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zP4cyDs-Rdbp"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mchanwa/COS424/blob/main/Homework2_Fragile_Families_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP4cyDs-Rdbp"
      },
      "source": [
        "# Imputation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJfLn6b6RjXY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def fillMissing(inputcsv, outputcsv):\n",
        "    \n",
        "    # read input csv - takes time\n",
        "    df = pd.read_csv(inputcsv, low_memory=False)\n",
        "    # Fix date bug\n",
        "    df.cf4fint = ((pd.to_datetime(df.cf4fint) - pd.to_datetime('1960-01-01')) / np.timedelta64(1, 'D')).astype(int)\n",
        "    \n",
        "    # replace NA's with mode\n",
        "    df = df.fillna(df.mode().iloc[0])\n",
        "    # if still NA, replace with 1\n",
        "    df = df.fillna(value=1)\n",
        "    # replace negative values with 1\n",
        "    num = df._get_numeric_data()\n",
        "    num[num < 0] = 1\n",
        "    # write filled outputcsv\n",
        "    df.to_csv(outputcsv, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwAZphi_RqRT"
      },
      "source": [
        "  from os.path import join as pjoin\n",
        "  data_dir = \"drive/MyDrive/FFChallenge_v5\"\n",
        "\n",
        "  ## impute the background data\n",
        "  in_path = pjoin(data_dir, 'background.csv')\n",
        "  out_path = pjoin(data_dir, 'background_clean.csv')\n",
        "  fillMissing(in_path, out_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9VvSm6C8ugN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db53232d-cdee-40a5-b848-769470129b48"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeFEwKs5S7Ns"
      },
      "source": [
        "background = pd.read_csv(in_path, low_memory=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPeLVdRWTOx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c961ab-15c2-4ef9-8219-1c16f3d06d40"
      },
      "source": [
        "backgroundClean = pd.read_csv(out_path, low_memory=False)\n",
        "backgroundClean.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>challengeID</th>\n",
              "      <th>cf1intmon</th>\n",
              "      <th>cf1intyr</th>\n",
              "      <th>cf1lenhr</th>\n",
              "      <th>cf1lenmin</th>\n",
              "      <th>cf1twoc</th>\n",
              "      <th>cf1fint</th>\n",
              "      <th>cf1natsm</th>\n",
              "      <th>f1natwt</th>\n",
              "      <th>cf1natsmx</th>\n",
              "      <th>f1natwtx</th>\n",
              "      <th>cf1citsm</th>\n",
              "      <th>f1citywt</th>\n",
              "      <th>f1a2</th>\n",
              "      <th>f1a3</th>\n",
              "      <th>f1a4</th>\n",
              "      <th>f1a4a</th>\n",
              "      <th>f1a5</th>\n",
              "      <th>f1a5a</th>\n",
              "      <th>f1a6</th>\n",
              "      <th>f1a6a</th>\n",
              "      <th>f1a7</th>\n",
              "      <th>cf1age</th>\n",
              "      <th>f1b1a</th>\n",
              "      <th>f1b1b</th>\n",
              "      <th>f1b2</th>\n",
              "      <th>f1b3</th>\n",
              "      <th>f1b4a</th>\n",
              "      <th>f1b4b</th>\n",
              "      <th>f1b4c</th>\n",
              "      <th>f1b4d</th>\n",
              "      <th>f1b4e</th>\n",
              "      <th>f1b4f</th>\n",
              "      <th>f1b4g</th>\n",
              "      <th>f1b5a</th>\n",
              "      <th>f1b5b</th>\n",
              "      <th>f1b5c</th>\n",
              "      <th>f1b5d</th>\n",
              "      <th>f1b6a</th>\n",
              "      <th>f1b6b</th>\n",
              "      <th>...</th>\n",
              "      <th>q5citywt_rep58</th>\n",
              "      <th>q5citywt_rep59</th>\n",
              "      <th>q5citywt_rep60</th>\n",
              "      <th>q5citywt_rep61</th>\n",
              "      <th>q5citywt_rep62</th>\n",
              "      <th>q5citywt_rep63</th>\n",
              "      <th>q5citywt_rep64</th>\n",
              "      <th>q5citywt_rep65</th>\n",
              "      <th>q5citywt_rep66</th>\n",
              "      <th>q5citywt_rep67</th>\n",
              "      <th>q5citywt_rep68</th>\n",
              "      <th>q5citywt_rep69</th>\n",
              "      <th>q5citywt_rep70</th>\n",
              "      <th>q5citywt_rep71</th>\n",
              "      <th>q5citywt_rep72</th>\n",
              "      <th>m1b7</th>\n",
              "      <th>m1b13</th>\n",
              "      <th>m1b25</th>\n",
              "      <th>f1b7</th>\n",
              "      <th>f1b13</th>\n",
              "      <th>f1b25</th>\n",
              "      <th>m2d6</th>\n",
              "      <th>m2d8</th>\n",
              "      <th>m3d7</th>\n",
              "      <th>m3d9</th>\n",
              "      <th>m3e23</th>\n",
              "      <th>f3d7</th>\n",
              "      <th>f3d9</th>\n",
              "      <th>m4d6</th>\n",
              "      <th>m4d7</th>\n",
              "      <th>m4d9</th>\n",
              "      <th>m4e23</th>\n",
              "      <th>f4d6</th>\n",
              "      <th>f4d7</th>\n",
              "      <th>f4d9</th>\n",
              "      <th>m5c6</th>\n",
              "      <th>m5d20</th>\n",
              "      <th>m5k10</th>\n",
              "      <th>f5c6</th>\n",
              "      <th>k5f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>8.529998</td>\n",
              "      <td>16.918385</td>\n",
              "      <td>18.157625</td>\n",
              "      <td>9.367338</td>\n",
              "      <td>4.486860</td>\n",
              "      <td>7.617537</td>\n",
              "      <td>20.945231</td>\n",
              "      <td>7.307182</td>\n",
              "      <td>0.949437</td>\n",
              "      <td>3.873586</td>\n",
              "      <td>5.754821</td>\n",
              "      <td>1.442153</td>\n",
              "      <td>7.356769</td>\n",
              "      <td>2.351121</td>\n",
              "      <td>1.235117</td>\n",
              "      <td>6.269946</td>\n",
              "      <td>5.180325</td>\n",
              "      <td>2.511131</td>\n",
              "      <td>1.718804</td>\n",
              "      <td>6.473537</td>\n",
              "      <td>16.369411</td>\n",
              "      <td>4.476881</td>\n",
              "      <td>9.628369</td>\n",
              "      <td>15.981275</td>\n",
              "      <td>24.038266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>68.455658</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>8.529998</td>\n",
              "      <td>5.701997</td>\n",
              "      <td>7.337275</td>\n",
              "      <td>9.367338</td>\n",
              "      <td>15.415219</td>\n",
              "      <td>7.617537</td>\n",
              "      <td>20.945231</td>\n",
              "      <td>7.307182</td>\n",
              "      <td>0.949437</td>\n",
              "      <td>3.873586</td>\n",
              "      <td>25.380555</td>\n",
              "      <td>1.442153</td>\n",
              "      <td>7.356769</td>\n",
              "      <td>2.351121</td>\n",
              "      <td>1.235117</td>\n",
              "      <td>6.269946</td>\n",
              "      <td>27.680196</td>\n",
              "      <td>2.511131</td>\n",
              "      <td>1.718804</td>\n",
              "      <td>6.473537</td>\n",
              "      <td>16.369411</td>\n",
              "      <td>26.671897</td>\n",
              "      <td>9.628369</td>\n",
              "      <td>15.981275</td>\n",
              "      <td>3.667679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>42.319057</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>102</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>8.529998</td>\n",
              "      <td>16.918385</td>\n",
              "      <td>18.279081</td>\n",
              "      <td>9.367338</td>\n",
              "      <td>4.486860</td>\n",
              "      <td>18.553213</td>\n",
              "      <td>20.945231</td>\n",
              "      <td>7.307182</td>\n",
              "      <td>19.144806</td>\n",
              "      <td>3.873586</td>\n",
              "      <td>5.754821</td>\n",
              "      <td>19.800679</td>\n",
              "      <td>7.356769</td>\n",
              "      <td>2.351121</td>\n",
              "      <td>1.235117</td>\n",
              "      <td>6.269946</td>\n",
              "      <td>5.180325</td>\n",
              "      <td>20.867881</td>\n",
              "      <td>24.115867</td>\n",
              "      <td>6.473537</td>\n",
              "      <td>16.369411</td>\n",
              "      <td>4.476881</td>\n",
              "      <td>9.628369</td>\n",
              "      <td>15.981275</td>\n",
              "      <td>24.038266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>25.628830</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>8.529998</td>\n",
              "      <td>5.988335</td>\n",
              "      <td>7.337275</td>\n",
              "      <td>9.367338</td>\n",
              "      <td>16.084987</td>\n",
              "      <td>7.617537</td>\n",
              "      <td>2.802519</td>\n",
              "      <td>7.307182</td>\n",
              "      <td>19.144806</td>\n",
              "      <td>3.873586</td>\n",
              "      <td>5.754821</td>\n",
              "      <td>19.285963</td>\n",
              "      <td>7.356769</td>\n",
              "      <td>21.220233</td>\n",
              "      <td>23.172680</td>\n",
              "      <td>6.269946</td>\n",
              "      <td>5.180325</td>\n",
              "      <td>22.018875</td>\n",
              "      <td>22.932641</td>\n",
              "      <td>6.473537</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.476881</td>\n",
              "      <td>9.628369</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.140511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41.954487</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>8.529998</td>\n",
              "      <td>5.988335</td>\n",
              "      <td>7.337275</td>\n",
              "      <td>9.367338</td>\n",
              "      <td>15.293944</td>\n",
              "      <td>7.617537</td>\n",
              "      <td>2.748267</td>\n",
              "      <td>7.307182</td>\n",
              "      <td>19.867851</td>\n",
              "      <td>3.873586</td>\n",
              "      <td>5.754821</td>\n",
              "      <td>20.121984</td>\n",
              "      <td>7.356769</td>\n",
              "      <td>21.386605</td>\n",
              "      <td>23.227584</td>\n",
              "      <td>6.269946</td>\n",
              "      <td>5.180325</td>\n",
              "      <td>22.916602</td>\n",
              "      <td>22.988036</td>\n",
              "      <td>6.473537</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.476881</td>\n",
              "      <td>9.628369</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.668879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 13027 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   challengeID  cf1intmon  cf1intyr  ...     m5k10       f5c6       k5f1\n",
              "0            1          1         1  ...  9.628369  15.981275  24.038266\n",
              "1            2          1         1  ...  9.628369  15.981275   3.667679\n",
              "2            3          1         1  ...  9.628369  15.981275  24.038266\n",
              "3            4          1         1  ...  9.628369   1.000000   4.140511\n",
              "4            5          1         1  ...  9.628369   1.000000   3.668879\n",
              "\n",
              "[5 rows x 13027 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T18rHl2DTq03"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEdXI9-CFLVA"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQpZaWLsMBfg"
      },
      "source": [
        "### Without Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZlEBhLBqNIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02ebb8b-0b1b-4a62-9088-b3918d517288"
      },
      "source": [
        "#one-hot encoding\n",
        "#https://towardsdatascience.com/encoding-categorical-features-21a2651a065c\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def oneHotEncode(df):\n",
        "  le = LabelEncoder()\n",
        "  # Categorical boolean mask\n",
        "  categorical_feature_mask = df.dtypes==object\n",
        "  # filter categorical columns using mask and turn it into a list\n",
        "  categorical_cols = df.columns[categorical_feature_mask].tolist()\n",
        "  if (len(categorical_cols) == 0):\n",
        "    return\n",
        "\n",
        "  df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "y = pd.read_csv(pjoin(data_dir, 'train.csv'), low_memory=False)\n",
        "X = backgroundClean.loc[backgroundClean['challengeID'].isin(y['challengeID'])]\n",
        "\n",
        "oneHotEncode(X)\n",
        "oneHotEncode(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpcnqFsYHB15"
      },
      "source": [
        "data_gpa = (X.loc[X['challengeID'].isin(y[['challengeID', 'gpa']].dropna()['challengeID'])]).drop(columns=['challengeID'])\n",
        "data_grit = (X.loc[X['challengeID'].isin(y[['challengeID', 'grit']].dropna()['challengeID'])]).drop(columns=['challengeID'])\n",
        "data_materialHardship = (X.loc[X['challengeID'].isin(y[['challengeID', 'materialHardship']].dropna()['challengeID'])]).drop(columns=['challengeID'])\n",
        "data_eviction = (X.loc[X['challengeID'].isin(y[['challengeID', 'eviction']].dropna()['challengeID'])]).drop(columns=['challengeID'])\n",
        "data_layoff = (X.loc[X['challengeID'].isin(y[['challengeID', 'layoff']].dropna()['challengeID'])]).drop(columns=['challengeID'])\n",
        "data_jobTraining = (X.loc[X['challengeID'].isin(y[['challengeID', 'jobTraining']].dropna()['challengeID'])]).drop(columns=['challengeID'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDsRYI0vIxzT"
      },
      "source": [
        "outcomes_gpa = y['gpa'].dropna()\n",
        "outcomes_grit = y['grit'].dropna()\n",
        "outcomes_materialHardship = y['materialHardship'].dropna()\n",
        "outcomes_eviction = y['eviction'].dropna()\n",
        "outcomes_layoff = y['layoff'].dropna()\n",
        "outcomes_jobTraining = y['jobTraining'].dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZqMVTtHIbyf"
      },
      "source": [
        "train_data_gpa, test_data_gpa, train_outcomes_gpa, test_outcomes_gpa = train_test_split(data_gpa, outcomes_gpa, test_size=0.33, random_state=42)\n",
        "train_data_grit, test_data_grit, train_outcomes_grit, test_outcomes_grit = train_test_split(data_grit, outcomes_grit, test_size=0.33, random_state=42)\n",
        "train_data_materialHardship, test_data_materialHardship, train_outcomes_materialHardship, test_outcomes_materialHardship = train_test_split(data_materialHardship, outcomes_materialHardship, test_size=0.33, random_state=42)\n",
        "train_data_eviction, test_data_eviction, train_outcomes_eviction, test_outcomes_eviction = train_test_split(data_eviction, outcomes_eviction, test_size=0.33, random_state=42)\n",
        "train_data_layoff, test_data_layoff, train_outcomes_layoff, test_outcomes_layoff = train_test_split(data_layoff, outcomes_layoff, test_size=0.33, random_state=42)\n",
        "train_data_jobTraining, test_data_jobTraining, train_outcomes_jobTraining, test_outcomes_jobTraining = train_test_split(data_jobTraining, outcomes_jobTraining, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Gp-HDKzOss"
      },
      "source": [
        "all_train_data = backgroundClean.drop(columns=['challengeID'])\n",
        "oneHotEncode(all_train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZAc1VXyMIRq"
      },
      "source": [
        "### With Feature Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VEDgi-RL8Pv",
        "outputId": "64402956-fe39-4248-803f-1ae5ba302f1a"
      },
      "source": [
        "# 'selection percentile' feauture selection\n",
        "\n",
        "from sklearn.feature_selection import f_regression, SelectPercentile\n",
        "feature_selection_percentage = 50\n",
        "\n",
        "gpa_fs = SelectPercentile(f_regression, percentile=feature_selection_percentage)\n",
        "data_gpa_fs = gpa_fs.fit_transform(data_gpa, outcomes_gpa)\n",
        "\n",
        "grit_fs = SelectPercentile(f_regression, percentile=feature_selection_percentage)\n",
        "data_grit_fs = grit_fs.fit_transform(data_grit, outcomes_grit)\n",
        "\n",
        "materialHardship_fs = SelectPercentile(f_regression, percentile=feature_selection_percentage)\n",
        "data_materialHardship_fs = materialHardship_fs.fit_transform(data_materialHardship, outcomes_materialHardship)\n",
        "\n",
        "eviction_fs = SelectPercentile(f_regression, percentile=feature_selection_percentage)\n",
        "data_eviction_fs = eviction_fs.fit_transform(data_eviction, outcomes_eviction)\n",
        "\n",
        "layoff_fs = SelectPercentile(f_regression, percentile=feature_selection_percentage)\n",
        "data_layoff_fs = layoff_fs.fit_transform(data_layoff, outcomes_layoff)\n",
        "\n",
        "jobTraining_fs = SelectPercentile(f_regression, percentile=feature_selection_percentage)\n",
        "data_jobTraining_fs = jobTraining_fs.fit_transform(data_jobTraining, outcomes_jobTraining)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
            "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
            "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
            "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
            "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
            "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
            "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27KOR370L33g"
      },
      "source": [
        "train_data_gpa_fs, test_data_gpa_fs, train_outcomes_gpa_fs, test_outcomes_gpa_fs = train_test_split(data_gpa_fs, outcomes_gpa, test_size=0.33, random_state=42)\n",
        "train_data_grit_fs, test_data_grit_fs, train_outcomes_grit_fs, test_outcomes_grit_fs = train_test_split(data_grit_fs, outcomes_grit, test_size=0.33, random_state=42)\n",
        "train_data_materialHardship_fs, test_data_materialHardship_fs, train_outcomes_materialHardship_fs, test_outcomes_materialHardship_fs = train_test_split(data_materialHardship_fs, outcomes_materialHardship, test_size=0.33, random_state=42)\n",
        "train_data_eviction_fs, test_data_eviction_fs, train_outcomes_eviction_fs, test_outcomes_eviction_fs = train_test_split(data_eviction_fs, outcomes_eviction, test_size=0.33, random_state=42)\n",
        "train_data_layoff_fs, test_data_layoff_fs, train_outcomes_layoff_fs, test_outcomes_layoff_fs = train_test_split(data_layoff_fs, outcomes_layoff, test_size=0.33, random_state=42)\n",
        "train_data_jobTraining_fs, test_data_jobTraining_fs, train_outcomes_jobTraining_fs, test_outcomes_jobTraining_fs = train_test_split(data_jobTraining_fs, outcomes_jobTraining, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwXIUZAPQrCd"
      },
      "source": [
        "all_data_gpa_fs = gpa_fs.transform(all_train_data)\n",
        "all_data_grit_fs = grit_fs.transform(all_train_data)\n",
        "all_data_materialHardship_fs = materialHardship_fs.transform(all_train_data)\n",
        "all_data_eviction_fs = eviction_fs.transform(all_train_data)\n",
        "all_data_layoff_fs = layoff_fs.transform(all_train_data)\n",
        "all_data_jobTraining_fs = jobTraining_fs.transform(all_train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5S1Cs1-E8OD"
      },
      "source": [
        "## Linear Regression & Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XspBrZbjDGth"
      },
      "source": [
        "import statistics\n",
        "import time\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6aJn0D8O24s"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "def stats(outcome, true_y, pred_y, time):\n",
        "  # print('Coefficients: \\n', lr_eviction.)\n",
        "  # The mean squared error\n",
        "  print(outcome + \": \")\n",
        "  print('Mean squared error: %.2f'\n",
        "        % mean_squared_error(true_y, pred_y))\n",
        "  # The coefficient of determination: 1 is perfect prediction\n",
        "  print('Coefficient of determination: %.2f'\n",
        "        % r2_score(true_y, pred_y))\n",
        "  print('Time to fit and predict: ', time)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yuhik2x1T7AI",
        "outputId": "4f57d822-13a1-42dd-8384-6c9345f38549"
      },
      "source": [
        "# Linear Regression - without regularization\n",
        "\n",
        "# gpa\n",
        "start = time.time()\n",
        "lr_gpa = make_pipeline(StandardScaler(), LinearRegression()).fit(train_data_gpa, train_outcomes_gpa)\n",
        "lr_prediction_gpa = lr_gpa.predict(test_data_gpa)\n",
        "prediction_gpa_all = lr_gpa.predict(all_train_data)\n",
        "end = time.time()\n",
        "stats('gpa', test_outcomes_gpa, lr_prediction_gpa, end-start)\n",
        "\n",
        "# grit\n",
        "start = time.time()\n",
        "lr_grit = make_pipeline(StandardScaler(), LinearRegression()).fit(train_data_grit, train_outcomes_grit)\n",
        "lr_prediction_grit = lr_grit.predict(test_data_grit)\n",
        "prediction_grit_all = lr_grit.predict(all_train_data)\n",
        "end = time.time()\n",
        "stats('grit', test_outcomes_grit, lr_prediction_grit, end-start)\n",
        "\n",
        "# materialHardship\n",
        "start = time.time()\n",
        "lr_materialHardship = make_pipeline(StandardScaler(), LinearRegression()).fit(train_data_materialHardship, train_outcomes_materialHardship)\n",
        "lr_prediction_materialHardship = lr_materialHardship.predict(test_data_materialHardship)\n",
        "prediction_materialHardship_all = lr_materialHardship.predict(all_train_data)\n",
        "end = time.time()\n",
        "stats('materialHardship', test_outcomes_materialHardship, lr_prediction_materialHardship, end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpa: \n",
            "Mean squared error: 0.72\n",
            "Coefficient of determination: -0.69\n",
            "Time to fit and predict:  4.80043363571167\n",
            "\n",
            "grit: \n",
            "Mean squared error: 0.38\n",
            "Coefficient of determination: -0.52\n",
            "Time to fit and predict:  6.069481134414673\n",
            "\n",
            "materialHardship: \n",
            "Mean squared error: 0.03\n",
            "Coefficient of determination: -0.25\n",
            "Time to fit and predict:  6.260276794433594\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqd5oWhDze0b",
        "outputId": "e1bcc31d-4372-4fa6-a0e0-83627f98f8bd"
      },
      "source": [
        "# Linear Regression - with Lasso regularization\n",
        "\n",
        "# gpa\n",
        "start = time.time()\n",
        "lr_gpa = make_pipeline(StandardScaler(), linear_model.Lasso(alpha=0.02)).fit(train_data_gpa, train_outcomes_gpa)\n",
        "lr_prediction_gpa = lr_gpa.predict(test_data_gpa)\n",
        "prediction_gpa_all = lr_gpa.predict(all_train_data)\n",
        "end = time.time()\n",
        "stats('gpa', test_outcomes_gpa, lr_prediction_gpa, end-start)\n",
        "\n",
        "# grit\n",
        "start = time.time()\n",
        "lr_grit = make_pipeline(StandardScaler(), linear_model.Lasso(alpha=0.03)).fit(train_data_grit, train_outcomes_grit)\n",
        "lr_prediction_grit = lr_grit.predict(test_data_grit)\n",
        "prediction_grit_all = lr_grit.predict(all_train_data)\n",
        "end = time.time()\n",
        "stats('grit', test_outcomes_grit, lr_prediction_grit, end-start)\n",
        "\n",
        "# materialHardship\n",
        "start = time.time()\n",
        "lr_materialHardship = make_pipeline(StandardScaler(), linear_model.Lasso(alpha=0.04)).fit(train_data_materialHardship, train_outcomes_materialHardship)\n",
        "lr_prediction_materialHardship = lr_materialHardship.predict(test_data_materialHardship)\n",
        "prediction_materialHardship_all = lr_materialHardship.predict(all_train_data)\n",
        "end = time.time()\n",
        "stats('materialHardship', test_outcomes_materialHardship, lr_prediction_materialHardship, end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpa: \n",
            "Mean squared error: 0.42\n",
            "Coefficient of determination: 0.02\n",
            "Time to fit and predict:  5.140465974807739\n",
            "\n",
            "grit: \n",
            "Mean squared error: 0.25\n",
            "Coefficient of determination: 0.01\n",
            "Time to fit and predict:  1.7099504470825195\n",
            "\n",
            "materialHardship: \n",
            "Mean squared error: 0.02\n",
            "Coefficient of determination: 0.02\n",
            "Time to fit and predict:  1.2375309467315674\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EffQr90jzuEI",
        "outputId": "cbf33e9f-4baa-4370-a447-abe2f5580296"
      },
      "source": [
        "# Linear Regression - with Ridge (l2) regularization\n",
        "\n",
        "# gpa\n",
        "start = time.time()\n",
        "lr_gpa = make_pipeline(StandardScaler(), linear_model.Ridge(alpha=0.1)).fit(train_data_gpa, train_outcomes_gpa)\n",
        "lr_prediction_gpa = lr_gpa.predict(test_data_gpa)\n",
        "prediction_gpa_all = lr_gpa.predict(all_train_data)\n",
        "end = time.time()\n",
        "stats('gpa', test_outcomes_gpa, lr_prediction_gpa, end-start)\n",
        "\n",
        "# grit\n",
        "start = time.time()\n",
        "lr_grit = make_pipeline(StandardScaler(), linear_model.Ridge(alpha=0.1)).fit(train_data_grit, train_outcomes_grit)\n",
        "lr_prediction_grit = lr_grit.predict(test_data_grit)\n",
        "prediction_grit_all = lr_grit.predict(all_train_data)\n",
        "end = time.time()\n",
        "stats('grit', test_outcomes_grit, lr_prediction_grit, end-start)\n",
        "\n",
        "# materialHardship\n",
        "start = time.time()\n",
        "lr_materialHardship = make_pipeline(StandardScaler(), linear_model.Ridge(alpha=0.1)).fit(train_data_materialHardship, train_outcomes_materialHardship)\n",
        "lr_prediction_materialHardship = lr_materialHardship.predict(test_data_materialHardship)\n",
        "prediction_materialHardship_all = lr_materialHardship.predict(all_train_data)\n",
        "end = time.time()\n",
        "stats('materialHardship', test_outcomes_materialHardship, lr_prediction_materialHardship, end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpa: \n",
            "Mean squared error: 0.72\n",
            "Coefficient of determination: -0.67\n",
            "Time to fit and predict:  1.3396031856536865\n",
            "\n",
            "grit: \n",
            "Mean squared error: 0.38\n",
            "Coefficient of determination: -0.52\n",
            "Time to fit and predict:  1.5349390506744385\n",
            "\n",
            "materialHardship: \n",
            "Mean squared error: 0.03\n",
            "Coefficient of determination: -0.25\n",
            "Time to fit and predict:  1.5779428482055664\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxkD276kCyhK",
        "outputId": "bd675d10-170d-45d2-90f0-7dd0363b8f9f"
      },
      "source": [
        "# Logistic regression - binary data\n",
        "\n",
        "# eviction\n",
        "start = time.time()\n",
        "lr_eviction = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)).fit(train_data_eviction, train_outcomes_eviction)\n",
        "lr_prediction_eviction = lr_eviction.predict(test_data_eviction)\n",
        "prediction_eviction_all = lr_eviction.predict(all_train_data)\n",
        "end = time.time()\n",
        "print(\"eviction: \")\n",
        "print(\"score = {0}\".format(lr_eviction.score(test_data_eviction, test_outcomes_eviction)))\n",
        "print(\"fit and predict time (Logistic Regression, eviction): \" + str(end-start))\n",
        "print()\n",
        "\n",
        "# layoff\n",
        "start = time.time()\n",
        "lr_layoff = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)).fit(train_data_layoff, train_outcomes_layoff)\n",
        "lr_prediction_layoff = lr_layoff.predict(test_data_layoff)\n",
        "prediction_layoff_all = lr_layoff.predict(all_train_data)\n",
        "end = time.time()\n",
        "print(\"layoff: \")\n",
        "print(\"score = {0}\".format(lr_layoff.score(test_data_layoff, test_outcomes_layoff)))\n",
        "print(\"fit and predict time (Logistic Regression, layoff): \" + str(end-start))\n",
        "print()\n",
        "\n",
        "# jobTraining\n",
        "start = time.time()\n",
        "lr_jobTraining = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)).fit(train_data_jobTraining, train_outcomes_jobTraining)\n",
        "lr_jobTraining_layoff = lr_jobTraining.predict(test_data_jobTraining)\n",
        "prediction_jobTraining_all = lr_jobTraining.predict(all_train_data)\n",
        "end = time.time()\n",
        "print(\"jobTraining: \")\n",
        "print(\"fit and predict time (Logistic Regression, jobTraining): \" + str(end-start))\n",
        "print(\"score = {0}\".format(lr_jobTraining.score(test_data_jobTraining, test_outcomes_jobTraining)))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eviction: \n",
            "score = 0.9398340248962656\n",
            "fit and predict time (Logistic Regression, eviction): 5.5950608253479\n",
            "\n",
            "layoff: \n",
            "score = 0.7630331753554502\n",
            "fit and predict time (Logistic Regression, layoff): 4.628309726715088\n",
            "\n",
            "jobTraining: \n",
            "fit and predict time (Logistic Regression, jobTraining): 5.4961183071136475\n",
            "score = 0.6977225672877847\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HRAQdKbtaKj",
        "outputId": "e9a15a71-6391-4f03-c8f0-e7891ec155ce"
      },
      "source": [
        "# Logistic regression with Feature Selection - binary data\n",
        "\n",
        "# eviction\n",
        "start = time.time()\n",
        "lr_eviction = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)).fit(train_data_eviction_fs, train_outcomes_eviction_fs)\n",
        "lr_prediction_eviction = lr_eviction.predict(test_data_eviction_fs)\n",
        "prediction_eviction_all = lr_eviction.predict(all_data_eviction_fs)\n",
        "end = time.time()\n",
        "print(\"eviction: \")\n",
        "print(\"score = {0}\".format(lr_eviction.score(test_data_eviction_fs, test_outcomes_eviction_fs)))\n",
        "print(\"fit and predict time (Logistic Regression, eviction): \" + str(end-start))\n",
        "print()\n",
        "\n",
        "# layoff\n",
        "start = time.time()\n",
        "lr_layoff = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)).fit(train_data_layoff_fs, train_outcomes_layoff_fs)\n",
        "lr_prediction_layoff = lr_layoff.predict(test_data_layoff_fs)\n",
        "prediction_layoff_all = lr_layoff.predict(all_data_layoff_fs)\n",
        "end = time.time()\n",
        "print(\"layoff: \")\n",
        "print(\"score = {0}\".format(lr_layoff.score(test_data_layoff_fs, test_outcomes_layoff_fs)))\n",
        "print(\"fit and predict time (Logistic Regression, layoff): \" + str(end-start))\n",
        "print()\n",
        "\n",
        "# jobTraining\n",
        "start = time.time()\n",
        "lr_jobTraining = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)).fit(train_data_jobTraining_fs, train_outcomes_jobTraining_fs)\n",
        "lr_prediction_jobTraining = lr_jobTraining.predict(test_data_jobTraining_fs)\n",
        "prediction_jobTraining_all = lr_jobTraining.predict(all_data_jobTraining_fs)\n",
        "end = time.time()\n",
        "print(\"jobTraining: \")\n",
        "print(\"fit and predict time (Logistic Regression, jobTraining): \" + str(end-start))\n",
        "print(\"score = {0}\".format(lr_jobTraining.score(test_data_jobTraining_fs, test_outcomes_jobTraining_fs)))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eviction: \n",
            "score = 0.9336099585062241\n",
            "fit and predict time (Logistic Regression, eviction): 0.23079395294189453\n",
            "\n",
            "layoff: \n",
            "score = 0.7819905213270142\n",
            "fit and predict time (Logistic Regression, layoff): 0.31537342071533203\n",
            "\n",
            "jobTraining: \n",
            "fit and predict time (Logistic Regression, jobTraining): 0.3763298988342285\n",
            "score = 0.7805383022774327\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gODRnLoLUf2Q"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def draw_scatter_plot(column, true_y, pred_y):\n",
        "  train_outcomes = pd.read_csv(pjoin(data_dir, 'train.csv'), low_memory=False)\n",
        "  oneHotEncode(train_outcomes)\n",
        "  rows_without_nan = [index for index, row in pd.DataFrame(train_outcomes[column]).iterrows() if not row.isnull().any()]\n",
        "  \n",
        "  plt.scatter(true_y, pred_y[rows_without_nan])\n",
        "  plt.title(column)\n",
        "  plt.xlabel('true_y')\n",
        "  plt.ylabel('pred_y')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "TCpSQK4CU3LG",
        "outputId": "6bc5344a-ff40-4f79-8cf3-ba2c584daa8a"
      },
      "source": [
        "draw_scatter_plot('gpa', train_outcomes_gpa, lr_prediction_gpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 22, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 44, 47, 51, 55, 56, 58, 59, 60, 63, 64, 65, 68, 70, 71, 72, 73, 79, 80, 81, 85, 89, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 104, 108, 110, 114, 116, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 130, 133, 134, 137, 141, 142, 143, 144, 153, 154, 155, 156, 159, 160, 162, 163, 165, 166, 168, 169, 171, 172, 173, 175, 177, 179, 181, 185, 187, 189, 192, 193, 194, 195, 196, 197, 200, 201, 205, 206, 210, 212, 213, 216, 218, 219, 220, 223, 224, 225, 227, 229, 230, 231, 232, 234, 235, 247, 252, 253, 255, 256, 257, 258, 261, 262, 265, 269, 270, 272, 273, 278, 283, 285, 287, 289, 291, 292, 294, 295, 296, 297, 298, 299, 303, 304, 305, 306, 307, 308, 309, 310, 311, 314, 319, 320, 321, 322, 323, 325, 326, 328, 329, 333, 334, 336, 337, 339, 344, 345, 346, 351, 352, 353, 354, 355, 357, 358, 361, 362, 363, 368, 369, 370, 372, 373, 376, 379, 380, 381, 382, 384, 385, 387, 389, 390, 391, 392, 394, 395, 397, 398, 399, 401, 402, 403, 406, 411, 412, 413, 414, 417, 419, 420, 422, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 437, 440, 441, 443, 445, 446, 447, 449, 450, 451, 455, 457, 458, 461, 462, 464, 466, 467, 468, 469, 473, 474, 478, 479, 480, 481, 482, 483, 484, 486, 488, 490, 491, 493, 496, 497, 498, 500, 502, 504, 505, 510, 513, 514, 516, 517, 519, 521, 523, 525, 529, 533, 535, 536, 537, 541, 543, 545, 548, 550, 552, 553, 554, 555, 556, 560, 561, 564, 565, 566, 568, 572, 575, 579, 580, 585, 587, 588, 591, 592, 593, 595, 598, 600, 601, 603, 604, 605, 608, 610, 612, 616, 618, 619, 620, 621, 622, 623, 627, 628, 629, 630, 631, 632, 633, 635, 636, 638, 639, 640, 641, 644, 647, 648, 650, 652, 654, 655, 656, 657, 660, 663, 667, 670, 671, 673, 674, 676, 678, 679, 680, 681, 683, 685, 695, 696, 698, 699, 701, 703, 704, 705, 706, 707, 711, 712, 713, 714, 716, 719, 720, 721, 727, 728, 731, 732, 734, 735, 736, 737, 738, 740, 741, 744, 745, 746, 748, 749, 750, 751, 752, 753, 755, 756, 757, 759, 760, 761, 762, 763, 765, 767, 768, 769, 773, 774, 775, 778, 781, 782, 786, 787, 790, 791, 792, 793, 795, 796, 797, 802, 804, 805, 806, 807, 812, 813, 814, 815, 817, 818, 819, 826, 827, 829, 830, 831, 833, 835, 836, 838, 842, 843, 844, 846, 848, 849, 851, 852, 853, 855, 857, 859, 860, 862, 863, 864, 867, 868, 871, 875, 880, 881, 882, 884, 885, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 898, 901, 903, 905, 906, 909, 912, 913, 915, 916, 920, 921, 923, 925, 926, 927, 928, 930, 932, 934, 935, 938, 939, 942, 945, 947, 950, 954, 955, 956, 958, 961, 962, 964, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 978, 981, 983, 984, 988, 989, 991, 992, 995, 997, 1000, 1002, 1004, 1005, 1010, 1013, 1014, 1015, 1016, 1018, 1020, 1022, 1023, 1027, 1028, 1030, 1032, 1033, 1035, 1036, 1038, 1040, 1041, 1042, 1043, 1044, 1048, 1049, 1050, 1051, 1053, 1055, 1056, 1057, 1058, 1059, 1060, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1073, 1077, 1079, 1084, 1085, 1086, 1088, 1091, 1094, 1095, 1096, 1097, 1099, 1101, 1102, 1103, 1104, 1105, 1109, 1110, 1111, 1113, 1115, 1116, 1117, 1119, 1122, 1123, 1125, 1126, 1127, 1128, 1129, 1131, 1132, 1138, 1142, 1143, 1146, 1147, 1152, 1155, 1159, 1161, 1162, 1165, 1168, 1169, 1170, 1171, 1172, 1173, 1177, 1179, 1181, 1185, 1186, 1187, 1188, 1193, 1194, 1195, 1196, 1198, 1200, 1201, 1202, 1204, 1206, 1210, 1212, 1215, 1218, 1220, 1221, 1222, 1225, 1226, 1229, 1230, 1234, 1235, 1238, 1239, 1242, 1245, 1246, 1247, 1248, 1252, 1254, 1256, 1261, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1275, 1276, 1278, 1281, 1282, 1285, 1286, 1288, 1289, 1290, 1291, 1293, 1297, 1298, 1299, 1301, 1304, 1305, 1306, 1311, 1313, 1314, 1315, 1317, 1318, 1319, 1320, 1321, 1323, 1324, 1325, 1326, 1331, 1332, 1333, 1334, 1336, 1339, 1340, 1341, 1346, 1350, 1351, 1352, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1363, 1364, 1365, 1366, 1367, 1368, 1374, 1377, 1378, 1380, 1383, 1385, 1388, 1390, 1391, 1395, 1396, 1399, 1400, 1403, 1404, 1406, 1407, 1408, 1410, 1411, 1414, 1415, 1416, 1418, 1419, 1420, 1425, 1426, 1427, 1429, 1430, 1431, 1432, 1433, 1435, 1437, 1439, 1440, 1442, 1447, 1448, 1450, 1452, 1454, 1455, 1456, 1458, 1459, 1461, 1465, 1466, 1468, 1469, 1473, 1474, 1476, 1477, 1480, 1481, 1483, 1484, 1485, 1486, 1487, 1488, 1490, 1491, 1492, 1493, 1494, 1495, 1500, 1501, 1502, 1505, 1507, 1508, 1509, 1510, 1514, 1515, 1516, 1520, 1521, 1524, 1525, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1538, 1539, 1540, 1543, 1545, 1546, 1548, 1549, 1550, 1551, 1552, 1553, 1556, 1558, 1559, 1562, 1563, 1565, 1569, 1570, 1571, 1572, 1574, 1575, 1576, 1577, 1580, 1581, 1582, 1584, 1585, 1587, 1588, 1589, 1590, 1594, 1596, 1598, 1602, 1605, 1606, 1609, 1610, 1612, 1613, 1616, 1618, 1620, 1622, 1623, 1624, 1628, 1629, 1631, 1633, 1634, 1635, 1636, 1638, 1643, 1645, 1646, 1647, 1649, 1650, 1651, 1652, 1653, 1654, 1656, 1659, 1660, 1661, 1663, 1665, 1667, 1668, 1669, 1671, 1672, 1676, 1677, 1678, 1681, 1682, 1685, 1686, 1687, 1690, 1691, 1692, 1693, 1695, 1697, 1698, 1699, 1703, 1704, 1705, 1707, 1708, 1709, 1710, 1712, 1713, 1715, 1716, 1719, 1720, 1721, 1722, 1724, 1725, 1726, 1728, 1731, 1732, 1734, 1735, 1738, 1742, 1744, 1747, 1748, 1750, 1751, 1752, 1753, 1755, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1766, 1767, 1768, 1769, 1770, 1772, 1773, 1775, 1776, 1777, 1779, 1781, 1782, 1783, 1786, 1787, 1793, 1794, 1795, 1799, 1800, 1801, 1804, 1805, 1807, 1809, 1811, 1812, 1815, 1817, 1818, 1820, 1822, 1824, 1828, 1829, 1833, 1834, 1835, 1838, 1840, 1841, 1843, 1844, 1846, 1850, 1851, 1852, 1853, 1854, 1856, 1857, 1858, 1859, 1863, 1865, 1867, 1868, 1872, 1876, 1877, 1878, 1879, 1883, 1884, 1886, 1887, 1889, 1893, 1895, 1897, 1898, 1901, 1903, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1917, 1918, 1919, 1921, 1923, 1924, 1925, 1926, 1928, 1933, 1935, 1936, 1938, 1943, 1944, 1952, 1954, 1957, 1958, 1960, 1962, 1964, 1965, 1966, 1967, 1968, 1970, 1971, 1972, 1973, 1977, 1979, 1980, 1983, 1985, 1989, 1990, 1991, 1992, 1993, 1994, 1997, 2000, 2002, 2003, 2009, 2010, 2011, 2014, 2015, 2017, 2018, 2019, 2020, 2021, 2023, 2025, 2026, 2027, 2028, 2029, 2035, 2036, 2038, 2040, 2042, 2044, 2048, 2049, 2050, 2052, 2053, 2055, 2056, 2057, 2059, 2060, 2063, 2064, 2065, 2072, 2073, 2076, 2077, 2081, 2082, 2084, 2086, 2087, 2088, 2090, 2091, 2095, 2102, 2104, 2106, 2108, 2110, 2114, 2118, 2120]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTG62_4UqIqR",
        "outputId": "f1c0dd66-0da4-4cd0-9cc2-ab4848244d7e"
      },
      "source": [
        "def cross_validation(classifier, numfolds):\n",
        "  cv_results_accuracy = \\\n",
        "    cross_validate(classifier, train_vocab_df, train_labels_arr, cv=numfolds, scoring='accuracy')\n",
        "  cv_results_recall = \\\n",
        "    cross_validate(classifier, train_vocab_df, train_labels_arr, cv=numfolds, scoring='recall')\n",
        "  cv_results_f1 = \\\n",
        "    cross_validate(classifier, train_vocab_df, train_labels_arr, cv=numfolds, scoring='f1')\n",
        "  cv_results_precision = \\\n",
        "    cross_validate(classifier, train_vocab_df, train_labels_arr, cv=numfolds, scoring='precision')\n",
        "\n",
        "  print(\"accuracy cv: \", statistics.mean(cv_results_accuracy['test_score']))\n",
        "  print(\"precision cv: \", statistics.mean(cv_results_precision['test_score']))\n",
        "  print(\"recall cv: \", statistics.mean(cv_results_recall['test_score']))\n",
        "  print(\"f1 cv: \", statistics.mean(cv_results_f1['test_score']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'fit_time': array([3.38650465, 3.20733905, 2.96887326, 3.53054237, 3.53649545]), 'score_time': array([0.11787295, 0.08345985, 0.09973311, 0.07309055, 0.10323691]), 'test_score': array([0.93835616, 0.94520548, 0.93835616, 0.93493151, 0.93127148])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyDEZv5wTIkT"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vftt340-TbCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b48cba0-ab39-4cd2-8e48-ec75e76b08e3"
      },
      "source": [
        "# KNN\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# eviction\n",
        "start = time.time()\n",
        "knn_eviction = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3)).fit(train_data_eviction, train_outcomes_eviction)\n",
        "lr_prediction_eviction = knn_eviction.predict(test_data_eviction)\n",
        "prediction_eviction_all = knn_eviction.predict(all_train_data)\n",
        "end = time.time()\n",
        "print(\"eviction: \")\n",
        "print(\"score = {0}\".format(knn_eviction.score(test_data_eviction, test_outcomes_eviction)))\n",
        "print(\"fit and predict time (KNN, eviction): \" + str(end-start))\n",
        "print()\n",
        "\n",
        "# layoff\n",
        "start = time.time()\n",
        "knn_layoff = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3)).fit(train_data_layoff, train_outcomes_layoff)\n",
        "lr_prediction_layoff = knn_layoff.predict(test_data_layoff)\n",
        "prediction_layoff_all = knn_layoff.predict(all_train_data)\n",
        "end = time.time()\n",
        "print(\"layoff: \")\n",
        "print(\"score = {0}\".format(knn_layoff.score(test_data_layoff, test_outcomes_layoff)))\n",
        "print(\"fit and predict time (KNN, layoff): \" + str(end-start))\n",
        "print()\n",
        "\n",
        "# jobTraining\n",
        "start = time.time()\n",
        "knn_jobTraining = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3)).fit(train_data_jobTraining, train_outcomes_jobTraining)\n",
        "lr_prediction_jobTraining = knn_jobTraining.predict(test_data_jobTraining)\n",
        "prediction_jobTraining_all = knn_jobTraining.predict(all_train_data)\n",
        "end = time.time()\n",
        "print(\"jobTraining: \")\n",
        "print(\"score = {0}\".format(knn_jobTraining.score(test_data_jobTraining, test_outcomes_jobTraining)))\n",
        "print(\"fit and predict time (KNN, jobTraining): \" + str(end-start))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eviction: \n",
            "score = 0.9439834024896265\n",
            "fit and predict time (KNN, eviction): 154.13661551475525\n",
            "\n",
            "layoff: \n",
            "score = 0.7748815165876777\n",
            "fit and predict time (KNN, layoff): 110.80797290802002\n",
            "\n",
            "jobTraining: \n",
            "score = 0.7370600414078675\n",
            "fit and predict time (KNN, jobTraining): 149.17587900161743\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LVcDGfNNTIC",
        "outputId": "7787d8ba-0155-4f7b-f2e2-b1212d1efc92"
      },
      "source": [
        "# KNN - with feature selection\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# eviction\n",
        "start = time.time()\n",
        "knn_eviction = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3)).fit(train_data_eviction_fs, train_outcomes_eviction_fs)\n",
        "lr_prediction_eviction = knn_eviction.predict(test_data_eviction_fs)\n",
        "prediction_eviction_all = knn_eviction.predict(all_data_eviction_fs)\n",
        "end = time.time()\n",
        "print(\"eviction: \")\n",
        "print(\"score = {0}\".format(knn_eviction.score(test_data_eviction_fs, test_outcomes_eviction_fs)))\n",
        "print(\"fit and predict time (KNN, eviction): \" + str(end-start))\n",
        "print()\n",
        "\n",
        "# layoff\n",
        "start = time.time()\n",
        "knn_layoff = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3)).fit(train_data_layoff_fs, train_outcomes_layoff_fs)\n",
        "lr_prediction_layoff = knn_layoff.predict(test_data_layoff_fs)\n",
        "prediction_layoff_all = knn_layoff.predict(all_data_layoff_fs)\n",
        "end = time.time()\n",
        "print(\"layoff: \")\n",
        "print(\"score = {0}\".format(knn_layoff.score(test_data_layoff_fs, test_outcomes_layoff_fs)))\n",
        "print(\"fit and predict time (KNN, layoff): \" + str(end-start))\n",
        "print()\n",
        "\n",
        "# jobTraining\n",
        "start = time.time()\n",
        "knn_jobTraining = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3)).fit(train_data_jobTraining_fs, train_outcomes_jobTraining_fs)\n",
        "lr_prediction_jobTraining = knn_jobTraining.predict(test_data_jobTraining_fs)\n",
        "prediction_jobTraining_all = knn_jobTraining.predict(all_data_jobTraining_fs)\n",
        "end = time.time()\n",
        "print(\"jobTraining: \")\n",
        "print(\"score = {0}\".format(knn_jobTraining.score(test_data_jobTraining_fs, test_outcomes_jobTraining_fs)))\n",
        "print(\"fit and predict time (KNN, jobTraining): \" + str(end-start))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eviction: \n",
            "score = 0.9439834024896265\n",
            "fit and predict time (KNN, eviction): 74.4458954334259\n",
            "\n",
            "layoff: \n",
            "score = 0.7772511848341233\n",
            "fit and predict time (KNN, layoff): 56.19696116447449\n",
            "\n",
            "jobTraining: \n",
            "score = 0.722567287784679\n",
            "fit and predict time (KNN, jobTraining): 75.23535299301147\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u-_RUYg_iKj"
      },
      "source": [
        "challengeIDs = backgroundClean['challengeID']\n",
        "predicted_outcomes = np.stack((challengeIDs,\n",
        "                               prediction_gpa_all,\n",
        "                               prediction_grit_all,\n",
        "                               prediction_materialHardship_all,\n",
        "                               prediction_eviction_all,\n",
        "                               prediction_layoff_all,\n",
        "                               prediction_jobTraining_all))\n",
        "predicted_outcomes = predicted_outcomes.T\n",
        "headers = ['challengeID','gpa','grit','materialHardship', 'eviction', 'layoff', 'jobTraining']\n",
        "pd.DataFrame(predicted_outcomes).to_csv(pjoin(data_dir, 'prediction.csv'), header=headers, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}